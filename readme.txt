@2015/1/18
today I decide to start my big winter holiday plan, I want just to do 3 things:
1. algorithm 
2. python
3. machine learning 
I do hope that git help me a lot, and my English will be improved slowly. As soon as I write something, evernote will be listed here.
@2015/1/18
Today I learned some basic data type, like: list, tuple, dic, set, and some control command like for, while, if-else in python

@2015/1/20 
Today I'd like to learn something about git

@2015/1/21 
Today I've learn some remote hub control and branch management 

@2015/1/22
Today I've learn function and switch implementation in python
I wrote a basic spider program

@2015/1/23
Today I've learn something about re and how to use python to write a spider

@2015/1/24
Spider project started today
machine learning algorithm 1 - gradient decent

@2015/1/30 
I've laid aside my big plan for several days for my poor computer's breakingdown.
It's very hard to do one thing from head to tail, but I will try my best.

@2015/1/31
I've learned somthing in walk file directory
command in linux: rm -f "directory name" 
It's a command to remove a non-empty directory

@2015/2/1
Today It's very important for me, because It's the fist day of febulary. I learned how to control cursorï¼ˆguang biao) in vim(which is very useful). 
And I've found some intersting book.
Python file end:
	str = fp.read();
	while (str == ''):
		str = fp.read();

@2015/2/2
Today I've implement a gradient decent algorithm in one varient.
USAGE OF Python function: sum:
sum([...]);
sum([function(item) for a[,b..] in list1.items() (if item in list2)]);
Use algorithm to recommend movies;
USAGE OF python dic.setdefault(key[,value]):
if key exists,return value
else set default value and return value;
@2015/2/3
Today I've learned successfully how to recommend movies or products to a customer

@2015/2/4
pinv(X): to calculate non-square matix 
theta = inv(x'*x)*x'*y = pinv(x)*y(latter is more convenient)

sigular Matrix X : |X| = 0;
degenerate Matrix X : r(X)<demension(V) intuition V is a vector space
starting to learn about search engine
python class definiation

@2015/2/5
learn beautifsoup module in python

@2015/2/6
Today I've learned something about Markdown who has some interesting and very easy syntax:

###  title
* + - list
~text~   index
~~text~~ inner line
**text**  or __text__ bold
*text* or _text_   italic
`code`
> reference
[text](url)   link
![text](url)  image


@2015/2/7
Today I've learned how to make formula in remarkable.
$$
VERY INTERESTING!

```  ``` : syntax highlighted
***  : horin line
==  == : highlighted 

ctr+o  : open a file
   +q :quit
   +e :extract to pdf
   +t :insert time
   +i : italic
   +a : select all
   +s : save
   +d :delete line
   +g :horizone line
   +l :insert link
   +z :undo
   +x :cut
   +c : copy
   +v :paste
   +b :bold
   +n :create new file

@2015/2/8
Today I've learned how to build my own blog with hexo

@2015/2/9
Today classmate reunion

@2015/2/14
Today is valentines day. 
I've Just put my plan down for a very long time. 
Today It's all about NN, which is very hard to understand.


@2015/2/16
These days, I've just spent a lot of times in some meaningless things.
Today, I finished NN in ANG's class,with lots of questions remained.

@2015/2/17
When I submit programming exersices on ex3-5, A strange hint always goes out: Do not include theta(1). That realy confused me. After wathing PDF again, I found that when we compute J(\Theta) we also do not include \theta_0, which is the same as computing {\partial \over {\partial\theta}}

All in all, I've just finished handwritten Digits Rrecognition.

@2015/2/18
Today I've just implement a luck_money program by python, which is very interesting.

@2015/2/19
SVM started today.
J = C*SUM(y*cost_1()+(1-y)*cos_0())+sum(t.^2);
What do deep learning really means? It's a unsupervised machine learning method used to get features from a huge data set.
w(THETA) is just the normal vector of a surface.
:w'*x+b=0
scaling to make min(w'*x+b)y = 1

How do lambda works?
-(J + \lambda*\theta)
these two part has different weight(which is depends on data), penalty lamda is the same.
@2015/2/27
It's has been a long time since last commitment. 6 days remains. 
